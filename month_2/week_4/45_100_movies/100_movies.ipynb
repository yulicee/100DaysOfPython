{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c848fc2-4c76-44e5-aee8-19cc64f115f9",
   "metadata": {},
   "source": [
    "# Scraping and Analyzing the Top 100 Movies of All Time\n",
    "\n",
    "In this project, I am going to scrape a list of the top 100 movies from an archived page of Empire Online—a reputable source for movie rankings and reviews.\n",
    "\n",
    "The goal is to:\n",
    "1. Extract the movie titles from the webpage.\n",
    "2. Reverse the order of the list so that it starts with the #1 movie.\n",
    "3. Save the list to a file for further use.\n",
    "4. Display the list in this notebook for quick reference.\n",
    "\n",
    "This exercise showcases the power of web scraping, a technique that allows me to programmatically extract and process information from the web, turning it into structured data that I can analyze or store."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7ec68b-b81d-44cf-b09a-ff65a2f962e7",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0558faed-f9eb-411c-9b07-98cda0f2282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee2dc26-dc3c-4e30-a7d0-0e8546b58825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902535f4-9958-4262-b764-2ca5505a5370",
   "metadata": {},
   "source": [
    "- `BeautifulSoup` from the `bs4` package: This is a powerful library for parsing HTML and XML documents. I'll use it to navigate the webpage's structure and extract the movie titles\n",
    "- `requests`: This library allows me to send HTTP requests to the webpage and retrieve its content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e187f659-fe91-4421-ba82-7b3bbfc384fc",
   "metadata": {},
   "source": [
    "### Fetching and Parsing the Webpage Content\n",
    "\n",
    "Now I reach out to the specified URL, which points to an archived version of Empire Online's \"Top 100 Movies\" list. The `requests.get()` method fetches the raw HTML content of the page.\n",
    "\n",
    "Once I have the HTML content, I pass it to `BeautifulSoup` for parsing. `BeautifulSoup` takes the raw HTML and converts it into a structured format, allowing me to easily navigate through the elements of the page and find the information I'm looking for—in this case, movie titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89bd81e-ed4d-4e5a-a415-024b5942fb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of the webpage to scrape\n",
    "URL = \"https://web.archive.org/web/20200518073855/https://www.empireonline.com/movies/features/best-movies-2/\"\n",
    "\n",
    "response = requests.get(URL)\n",
    "website_html = response.text\n",
    "\n",
    "soup = BeautifulSoup(website_html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87c2bec-5542-4a3c-9a58-e74f6b232589",
   "metadata": {},
   "source": [
    "### Extracting and Reversing the Movie Titles\n",
    "\n",
    "With the parsed HTML in hand, I now look for the specific elements that contain the movie titles. By inspecting the HTML structure of the webpage, I find that each movie title is contained within an `h3` tag with the class `\"title\"`.\n",
    "\n",
    "Using `soup.find_all()`, I locate all such tags and extract the text (i.e., the movie titles) from them. The titles are then stored in a list.\n",
    "\n",
    "However, the list I extracted starts with the 100th movie and ends with the 1st. To correct this, I need to reverse the order of the list so that it starts with the #1 movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0f642c-f5f6-47f8-a632-94004748a67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_movies = soup.find_all(name=\"h3\", class_=\"title\")\n",
    "\n",
    "movie_titles = [movie.getText() for movie in all_movies]\n",
    "movies = movie_titles[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322ed465-56f5-45e2-bf3e-b5e4a0ced52e",
   "metadata": {},
   "source": [
    "### Saving the Movie Titles to a File\n",
    "\n",
    "To ensure that my list of movies is preserved for future reference, I save it to a text file named `movies.txt`. I open the file in write mode (`\"w\"`) with UTF-8 encoding, which supports a wide range of characters, ensuring that even movies with special characters in their titles are saved correctly.\n",
    "\n",
    "Each movie title is written to the file on a new line, creating a clean and organized list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbedda02-ab17-4231-ae65-06202f8ce628",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"movies.txt\", mode=\"w\", encoding=\"utf-8\") as file:\n",
    "    for movie in movies:\n",
    "        file.write(f\"{movie}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbe4724-e261-49c8-8944-7addff67bc1f",
   "metadata": {},
   "source": [
    "### Displaying the Movie Titles in the Notebook\n",
    "\n",
    "For quick reference and to verify my work, I also display the list of movies directly within this notebook. This allows me to see the final result immediately, without needing to open the text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc817ec-73f0-4a62-bc3e-0b70cf510e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for movie in movies:\n",
    "    print(movie)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95161fcd-ff6f-48f8-9d6b-3cd90263b496",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Web scraping is a powerful tool that allows us to automate the process of gathering information from the web. In this notebook, I demonstrated how to scrape a list of the top 100 movies from a well-regarded source, process that data, and store it in a reusable format.\n",
    "\n",
    "This project not only provided me with a list of movies to enjoy but also showcased the essential steps in web scraping: fetching content, parsing HTML, extracting relevant data, and saving it for future use. Whether you're compiling lists, analyzing trends, or gathering data for research, web scraping is an invaluable skill that opens up a world of possibilities.\n",
    "\n",
    "Now that I have my list, the next step could be analyzing the genres, directors, or even the IMDb ratings of these movies. The potential applications are vast and exciting!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
